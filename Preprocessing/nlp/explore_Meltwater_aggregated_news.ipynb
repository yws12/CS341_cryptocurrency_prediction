{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kexin Yu\"\n",
    "__version__ = \"CS341, Stanford, Spring 2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_home = 'news-coin-aggregations'\n",
    "social_data_home = 'social-coin-aggregations'\n",
    "\n",
    "coin_of_interest = 'BTC.jsonl'\n",
    "\n",
    "def json_read_multiple_records(file):\n",
    "    for line in open(file, mode=\"r\"):\n",
    "        yield json.loads(line)   \n",
    "        \n",
    "records = list(json_read_multiple_records(os.path.join(news_data_home, coin_of_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['country', 'key_phrases', 'concepts', 'count', 'categories', 'per_hour_sentiment', 'per_hour_reach'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]['views'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1523919600000', '1523869200000', '1523894400000', '1523844000000', '1523923200000', '1523898000000', '1523872800000', '1523847600000', '1523851200000', '1523876400000', '1523901600000', '1523905200000', '1523880000000', '1523854800000', '1523908800000', '1523883600000', '1523858400000', '1523836800000', '1523912400000', '1523887200000', '1523862000000', '1523865600000', '1523890800000', '1523840400000', '1523916000000'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day0_sentiment_dict = records[0]['views']['per_hour_reach']['subViews']\n",
    "day0_sentiment_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-hour sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  news_neutral  news_positive  news_negative  \\\n",
      "datetime                                                                \n",
      "1485997200000  2017-02-01           2.0            4.0            0.0   \n",
      "1486004400000  2017-02-01           1.0            0.0            0.0   \n",
      "1486008000000  2017-02-01           1.0            0.0            0.0   \n",
      "1486011600000  2017-02-01           0.0            1.0            0.0   \n",
      "1486015200000  2017-02-01           1.0            0.0            0.0   \n",
      "\n",
      "               news_sentiment_mean  \n",
      "datetime                            \n",
      "1485997200000         6.666667e-01  \n",
      "1486004400000         0.000000e+00  \n",
      "1486008000000         9.694558e-07  \n",
      "1486011600000         1.000000e+00  \n",
      "1486015200000         1.652439e-08  \n",
      "                     date  news_neutral  news_positive  news_negative  \\\n",
      "datetime                                                                \n",
      "1523905200000  2018-04-16         384.0           11.0           24.0   \n",
      "1523908800000  2018-04-16         233.0          152.0           27.0   \n",
      "1523912400000  2018-04-16         598.0           38.0           13.0   \n",
      "1523916000000  2018-04-16         512.0           11.0            5.0   \n",
      "1523919600000  2018-04-16         296.0            8.0           20.0   \n",
      "\n",
      "               news_sentiment_mean  \n",
      "datetime                            \n",
      "1523905200000            -0.030016  \n",
      "1523908800000             0.302729  \n",
      "1523912400000             0.038287  \n",
      "1523916000000             0.011715  \n",
      "1523919600000            -0.034630  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sentiments = []\n",
    "\n",
    "for record in records:\n",
    "    daily_sentiment_dict = record['views']['per_hour_sentiment']['subViews']\n",
    "    \n",
    "    hour_ids = []\n",
    "    frames = []\n",
    "\n",
    "    for hour_id, d in daily_sentiment_dict.items():\n",
    "        if d:\n",
    "            hour_ids.append(hour_id)\n",
    "            frames.append(flatten_dict(d))\n",
    "\n",
    "    df = pd.DataFrame(frames)\n",
    "\n",
    "    df['datetime'] = pd.Series(hour_ids)\n",
    "    df['date'] = pd.Series([datetime.fromtimestamp(float(h)/1000).strftime('%Y-%m-%d') for h in hour_ids])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['counts_type', 'mean_type'], inplace=True)\n",
    "    \n",
    "    sentiments.append(df)\n",
    "    \n",
    "df_sentiment = pd.concat(sentiments)\n",
    "df_sentiment.drop(columns=['counts_counts_u'], inplace=True)\n",
    "df_sentiment.sort_index(inplace=True)\n",
    "df_sentiment.rename(columns={'counts_counts_n': 'news_neutral', \n",
    "                   'counts_counts_p': 'news_positive',\n",
    "                   'counts_counts_v': 'news_negative',\n",
    "                   'mean_statistics_MEAN': 'news_sentiment_mean'\n",
    "                  }, inplace=True)\n",
    "cols = ['date', 'news_neutral', 'news_positive', 'news_negative', 'news_sentiment_mean']\n",
    "df_sentiment = df_sentiment[cols]\n",
    "df_sentiment.fillna(0, inplace=True)\n",
    "print(df_sentiment.head())\n",
    "print(df_sentiment.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-hour document reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  news_reach_count\n",
      "datetime                                   \n",
      "1485997200000  2017-02-01          724308.0\n",
      "1486004400000  2017-02-01           11832.0\n",
      "1486008000000  2017-02-01           77971.0\n",
      "1486011600000  2017-02-01           46797.0\n",
      "1486015200000  2017-02-01             378.0\n",
      "                     date  news_reach_count\n",
      "datetime                                   \n",
      "1523905200000  2018-04-16       254154812.0\n",
      "1523908800000  2018-04-16       201147442.0\n",
      "1523912400000  2018-04-16       327878870.0\n",
      "1523916000000  2018-04-16       244126008.0\n",
      "1523919600000  2018-04-16       150643500.0\n"
     ]
    }
   ],
   "source": [
    "records[0]['views']['per_hour_reach']['subViews']\n",
    "\n",
    "reach = []\n",
    "\n",
    "for record in records:\n",
    "    daily_reach_dict = record['views']['per_hour_reach']['subViews']\n",
    "    \n",
    "    hour_ids = []\n",
    "    frames = []\n",
    "\n",
    "    for hour_id, d in daily_reach_dict.items():\n",
    "        if d:\n",
    "            hour_ids.append(hour_id)\n",
    "            frames.append(flatten_dict(d))\n",
    "\n",
    "    df = pd.DataFrame(frames)\n",
    "\n",
    "    df['datetime'] = pd.Series(hour_ids)\n",
    "    df['date'] = pd.Series([datetime.fromtimestamp(float(h)/1000).strftime('%Y-%m-%d') for h in hour_ids])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['sum_type'], inplace=True)\n",
    "    \n",
    "    reach.append(df)\n",
    "    \n",
    "df_reach = pd.concat(reach)\n",
    "df_reach.sort_index(inplace=True)\n",
    "df_reach.rename(columns={'sum_statistics_SUM': 'news_reach_count'}, inplace=True)\n",
    "cols = ['date', 'news_reach_count']\n",
    "df_reach = df_reach[cols]\n",
    "df_reach.fillna(0, inplace=True)\n",
    "print(df_reach.head())\n",
    "print(df_reach.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news_neutral</th>\n",
       "      <th>news_positive</th>\n",
       "      <th>news_negative</th>\n",
       "      <th>news_sentiment_mean</th>\n",
       "      <th>news_reach_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523905200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>384.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.030016</td>\n",
       "      <td>254154812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523908800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>233.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.302729</td>\n",
       "      <td>201147442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523912400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>598.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>327878870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523916000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>244126008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523919600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>296.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.034630</td>\n",
       "      <td>150643500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  news_neutral  news_positive  news_negative  \\\n",
       "datetime                                                                \n",
       "1523905200000  2018-04-16         384.0           11.0           24.0   \n",
       "1523908800000  2018-04-16         233.0          152.0           27.0   \n",
       "1523912400000  2018-04-16         598.0           38.0           13.0   \n",
       "1523916000000  2018-04-16         512.0           11.0            5.0   \n",
       "1523919600000  2018-04-16         296.0            8.0           20.0   \n",
       "\n",
       "               news_sentiment_mean  news_reach_count  \n",
       "datetime                                              \n",
       "1523905200000            -0.030016       254154812.0  \n",
       "1523908800000             0.302729       201147442.0  \n",
       "1523912400000             0.038287       327878870.0  \n",
       "1523916000000             0.011715       244126008.0  \n",
       "1523919600000            -0.034630       150643500.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_reach = df_sentiment.join(df_reach, lsuffix='', rsuffix='_right')\n",
    "df_sent_reach.drop([col for col in df_sent_reach.columns if '_right' in col],axis=1,inplace=True)\n",
    "df_sent_reach.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news_neutral</th>\n",
       "      <th>news_positive</th>\n",
       "      <th>news_negative</th>\n",
       "      <th>news_sentiment_mean</th>\n",
       "      <th>news_reach_count</th>\n",
       "      <th>news_daily_reach_count</th>\n",
       "      <th>news_daily_sentiment_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523815200000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>31482400.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523818800000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>189.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.066782</td>\n",
       "      <td>186640773.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523822400000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>163.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.023207</td>\n",
       "      <td>348485686.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523826000000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>64843407.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523829600000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>215.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>44556315.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523833200000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>179.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.072590</td>\n",
       "      <td>112344143.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523836800000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>174.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.056712</td>\n",
       "      <td>66559376.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523840400000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>239.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021286</td>\n",
       "      <td>43522242.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523844000000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>169.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.199768</td>\n",
       "      <td>305179908.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523847600000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>197.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>98037818.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523851200000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>254.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>110992701.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523854800000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.077833</td>\n",
       "      <td>37823549.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523858400000</th>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.011073</td>\n",
       "      <td>57437633.0</td>\n",
       "      <td>2.959193e+09</td>\n",
       "      <td>-0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523862000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>55333435.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523865600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>395.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.316969</td>\n",
       "      <td>142940648.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523869200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>627.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.249095</td>\n",
       "      <td>155164257.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523872800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>354.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>274105360.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523876400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>611.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.011915</td>\n",
       "      <td>344782765.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523880000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.176058</td>\n",
       "      <td>323194614.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523883600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>765.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.101042</td>\n",
       "      <td>337141975.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523887200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.044925</td>\n",
       "      <td>330029322.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523890800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>265.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>279876675.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523894400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>426.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.063970</td>\n",
       "      <td>356082845.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523898000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>465.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.104280</td>\n",
       "      <td>286874753.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523901600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>400.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>178490149.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523905200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>384.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.030016</td>\n",
       "      <td>254154812.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523908800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>233.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.302729</td>\n",
       "      <td>201147442.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523912400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>598.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>327878870.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523916000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>244126008.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523919600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>296.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.034630</td>\n",
       "      <td>150643500.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.120788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  news_neutral  news_positive  news_negative  \\\n",
       "datetime                                                                \n",
       "1523815200000  2018-04-15         263.0            6.0            5.0   \n",
       "1523818800000  2018-04-15         189.0            8.0           23.0   \n",
       "1523822400000  2018-04-15         163.0            7.0           11.0   \n",
       "1523826000000  2018-04-15         178.0            6.0            9.0   \n",
       "1523829600000  2018-04-15         215.0           10.0            9.0   \n",
       "1523833200000  2018-04-15         179.0            4.0           19.0   \n",
       "1523836800000  2018-04-15         174.0            7.0           18.0   \n",
       "1523840400000  2018-04-15         239.0            6.0           12.0   \n",
       "1523844000000  2018-04-15         169.0           52.0            7.0   \n",
       "1523847600000  2018-04-15         197.0            8.0           12.0   \n",
       "1523851200000  2018-04-15         254.0            5.0            7.0   \n",
       "1523854800000  2018-04-15          68.0            7.0           15.0   \n",
       "1523858400000  2018-04-15          70.0            9.0           10.0   \n",
       "1523862000000  2018-04-16          65.0          214.0           12.0   \n",
       "1523865600000  2018-04-16         395.0          213.0           14.0   \n",
       "1523869200000  2018-04-16         627.0          234.0           13.0   \n",
       "1523872800000  2018-04-16         354.0           40.0           23.0   \n",
       "1523876400000  2018-04-16         611.0           11.0           20.0   \n",
       "1523880000000  2018-04-16        1021.0          247.0           20.0   \n",
       "1523883600000  2018-04-16         765.0          100.0           12.0   \n",
       "1523887200000  2018-04-16         582.0           40.0           19.0   \n",
       "1523890800000  2018-04-16         265.0           24.0           21.0   \n",
       "1523894400000  2018-04-16         426.0           52.0           19.0   \n",
       "1523898000000  2018-04-16         465.0           78.0           19.0   \n",
       "1523901600000  2018-04-16         400.0           16.0           24.0   \n",
       "1523905200000  2018-04-16         384.0           11.0           24.0   \n",
       "1523908800000  2018-04-16         233.0          152.0           27.0   \n",
       "1523912400000  2018-04-16         598.0           38.0           13.0   \n",
       "1523916000000  2018-04-16         512.0           11.0            5.0   \n",
       "1523919600000  2018-04-16         296.0            8.0           20.0   \n",
       "\n",
       "               news_sentiment_mean  news_reach_count  news_daily_reach_count  \\\n",
       "datetime                                                                       \n",
       "1523815200000             0.004673        31482400.0            2.959193e+09   \n",
       "1523818800000            -0.066782       186640773.0            2.959193e+09   \n",
       "1523822400000            -0.023207       348485686.0            2.959193e+09   \n",
       "1523826000000            -0.015032        64843407.0            2.959193e+09   \n",
       "1523829600000             0.003687        44556315.0            2.959193e+09   \n",
       "1523833200000            -0.072590       112344143.0            2.959193e+09   \n",
       "1523836800000            -0.056712        66559376.0            2.959193e+09   \n",
       "1523840400000            -0.021286        43522242.0            2.959193e+09   \n",
       "1523844000000             0.199768       305179908.0            2.959193e+09   \n",
       "1523847600000            -0.018803        98037818.0            2.959193e+09   \n",
       "1523851200000            -0.002113       110992701.0            2.959193e+09   \n",
       "1523854800000            -0.077833        37823549.0            2.959193e+09   \n",
       "1523858400000            -0.011073        57437633.0            2.959193e+09   \n",
       "1523862000000             0.693652        55333435.0            4.241967e+09   \n",
       "1523865600000             0.316969       142940648.0            4.241967e+09   \n",
       "1523869200000             0.249095       155164257.0            4.241967e+09   \n",
       "1523872800000             0.038696       274105360.0            4.241967e+09   \n",
       "1523876400000            -0.011915       344782765.0            4.241967e+09   \n",
       "1523880000000             0.176058       323194614.0            4.241967e+09   \n",
       "1523883600000             0.101042       337141975.0            4.241967e+09   \n",
       "1523887200000             0.044925       330029322.0            4.241967e+09   \n",
       "1523890800000             0.007041       279876675.0            4.241967e+09   \n",
       "1523894400000             0.063970       356082845.0            4.241967e+09   \n",
       "1523898000000             0.104280       286874753.0            4.241967e+09   \n",
       "1523901600000            -0.018507       178490149.0            4.241967e+09   \n",
       "1523905200000            -0.030016       254154812.0            4.241967e+09   \n",
       "1523908800000             0.302729       201147442.0            4.241967e+09   \n",
       "1523912400000             0.038287       327878870.0            4.241967e+09   \n",
       "1523916000000             0.011715       244126008.0            4.241967e+09   \n",
       "1523919600000            -0.034630       150643500.0            4.241967e+09   \n",
       "\n",
       "               news_daily_sentiment_mean  \n",
       "datetime                                  \n",
       "1523815200000                  -0.024093  \n",
       "1523818800000                  -0.024093  \n",
       "1523822400000                  -0.024093  \n",
       "1523826000000                  -0.024093  \n",
       "1523829600000                  -0.024093  \n",
       "1523833200000                  -0.024093  \n",
       "1523836800000                  -0.024093  \n",
       "1523840400000                  -0.024093  \n",
       "1523844000000                  -0.024093  \n",
       "1523847600000                  -0.024093  \n",
       "1523851200000                  -0.024093  \n",
       "1523854800000                  -0.024093  \n",
       "1523858400000                  -0.024093  \n",
       "1523862000000                   0.120788  \n",
       "1523865600000                   0.120788  \n",
       "1523869200000                   0.120788  \n",
       "1523872800000                   0.120788  \n",
       "1523876400000                   0.120788  \n",
       "1523880000000                   0.120788  \n",
       "1523883600000                   0.120788  \n",
       "1523887200000                   0.120788  \n",
       "1523890800000                   0.120788  \n",
       "1523894400000                   0.120788  \n",
       "1523898000000                   0.120788  \n",
       "1523901600000                   0.120788  \n",
       "1523905200000                   0.120788  \n",
       "1523908800000                   0.120788  \n",
       "1523912400000                   0.120788  \n",
       "1523916000000                   0.120788  \n",
       "1523919600000                   0.120788  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_reach['news_daily_reach_count'] = df_sent_reach['news_reach_count'].groupby(df_sent_reach['date']).transform('sum')\n",
    "df_sent_reach['news_daily_sentiment_mean'] = df_sent_reach['news_sentiment_mean'].groupby(df_sent_reach['date']).transform('mean')\n",
    "df_sent_reach.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_reach.to_pickle('df_hourly_news_sentiment_reach.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_bag_of_words(word_of_interest):\n",
    "    \"\"\"Collect all words from the given category and sort by count. \n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    timestamps = []\n",
    "\n",
    "    for record in records:\n",
    "        dict_ = record['views'][word_of_interest]['counts']\n",
    "        sorted_dict = sorted(dict_.items(), key=lambda x: x[1], reverse=True)\n",
    "        lst.append(sorted_dict)\n",
    "        timestamps.append(sorted(list(record['views']['per_hour_sentiment']['counts'].keys()))[0])\n",
    "    \n",
    "    dates = [datetime.fromtimestamp(float(ts)/1000).strftime('%Y-%m-%d') for ts in timestamps]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {'date': dates,\n",
    "         word_of_interest: lst,\n",
    "        })\n",
    "\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "                                \n",
    "    return df\n",
    "\n",
    "def phrase_to_words(df, word_of_interest):\n",
    "    \"\"\"Split phrase to words. \n",
    "    Example: ('Has Been', 17) -> ('Has', 17), ('Been', 17)\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        l1 = []\n",
    "        for pair in row[word_of_interest]:\n",
    "            l2 = []\n",
    "            for word in pair[0].split():\n",
    "                l2.append((word, pair[1]))\n",
    "            l1.extend(l2)\n",
    "        row[word_of_interest] = l1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     concepts\n",
      "date                                                         \n",
      "2017-02-01  [(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...\n",
      "2017-02-02  [(Bitcoin, 37), (United, 17), (States, 17), (J...\n",
      "2017-02-03  [(Bitcoin, 15), (Cryptocurrency, 6), (For, 3),...\n",
      "2017-02-04  [(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...\n",
      "2017-02-05  [(Bitcoin, 33), (Anonymity, 11), (United, 10),...\n",
      "                                                     concepts\n",
      "date                                                         \n",
      "2018-04-11  [(Cryptocurrency, 11223), (Bitcoin, 9098), (Un...\n",
      "2018-04-12  [(Cryptocurrency, 12276), (Bitcoin, 9985), (Tw...\n",
      "2018-04-13  [(Cryptocurrency, 6498), (Bitcoin, 4296), (Uni...\n",
      "2018-04-14  [(Cryptocurrency, 5758), (Bitcoin, 3738), (Uni...\n",
      "2018-04-15  [(Cryptocurrency, 13378), (Bitcoin, 10470), (U...\n"
     ]
    }
   ],
   "source": [
    "df_concept = get_bag_of_words('concepts')\n",
    "df_concept = phrase_to_words(df_concept, 'concepts')\n",
    "print(df_concept.head())\n",
    "print(df_concept.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  key_phrases\n",
      "date                                                         \n",
      "2017-02-01  [(company, 13), (companies, 12), (digital, 12)...\n",
      "2017-02-02  [(company, 15), (Bitcoin, 15), (investors, 9),...\n",
      "2017-02-03  [(data, 5), (services, 5), (business, 3), (Pet...\n",
      "2017-02-04  [(data, 3), (President, 2), (companies, 2), (c...\n",
      "2017-02-05  [(company, 8), (state, 7), (users, 7), (collab...\n",
      "                                                  key_phrases\n",
      "date                                                         \n",
      "2018-04-11  [(dollar, 2334), (Investors, 2287), (exchanges...\n",
      "2018-04-12  [(dollar, 2613), (exchanges, 2487), (Investors...\n",
      "2018-04-13  [(dollar, 2464), (Investors, 2365), (exchanges...\n",
      "2018-04-14  [(dollar, 2360), (Investors, 2254), (exchanges...\n",
      "2018-04-15  [(dollar, 2852), (Investors, 2822), (exchanges...\n"
     ]
    }
   ],
   "source": [
    "df_keyword = get_bag_of_words('key_phrases')\n",
    "df_keyword = phrase_to_words(df_keyword, 'key_phrases')\n",
    "print(df_keyword.head())\n",
    "print(df_keyword.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   categories\n",
      "date                                                         \n",
      "2017-02-01  [(Business, 53), (Finance, 48), (Technology, 4...\n",
      "2017-02-02  [(Business, 39), (Finance, 36), (Computers, 31...\n",
      "2017-02-03  [(Business, 16), (Information Technology, 14),...\n",
      "2017-02-04  [(Business, 19), (Finance, 18), (E-commerce, 1...\n",
      "2017-02-05  [(Business, 33), (Finance, 33), (Information T...\n",
      "                                                   categories\n",
      "date                                                         \n",
      "2018-04-11  [(Business, 9238), (Finance, 9044), (Informati...\n",
      "2018-04-12  [(Business, 10136), (Finance, 9918), (Informat...\n",
      "2018-04-13  [(Business, 4472), (Finance, 4162), (Informati...\n",
      "2018-04-14  [(Business, 3809), (Finance, 3646), (Informati...\n",
      "2018-04-15  [(Business, 10886), (Finance, 10488), (Technol...\n"
     ]
    }
   ],
   "source": [
    "df_category = get_bag_of_words('categories')\n",
    "print(df_category.head())\n",
    "print(df_category.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      country\n",
      "date                                                         \n",
      "2017-02-01  [(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...\n",
      "2017-02-02  [(us, 28), (gb, 3), (in, 2), (au, 1), (pt, 1),...\n",
      "2017-02-03              [(us, 13), (ru, 1), (fr, 1), (ca, 1)]\n",
      "2017-02-04  [(us, 15), (in, 1), (ph, 1), (ng, 1), (cn, 1),...\n",
      "2017-02-05  [(us, 18), (ca, 3), (in, 2), (gb, 2), (be, 1),...\n",
      "                                                      country\n",
      "date                                                         \n",
      "2018-04-11  [(us, 7540), (gb, 292), (ng, 247), (in, 191), ...\n",
      "2018-04-12  [(us, 8463), (gb, 237), (ng, 205), (in, 180), ...\n",
      "2018-04-13  [(us, 3660), (ng, 244), (in, 88), (gb, 68), (a...\n",
      "2018-04-14  [(us, 3114), (ng, 111), (in, 80), (gb, 74), (s...\n",
      "2018-04-15  [(us, 9522), (gb, 210), (ng, 186), (ca, 159), ...\n"
     ]
    }
   ],
   "source": [
    "df_country= get_bag_of_words('country')\n",
    "print(df_country.head())\n",
    "print(df_country.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concepts</th>\n",
       "      <th>key_phrases</th>\n",
       "      <th>categories</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>[(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...</td>\n",
       "      <td>[(company, 13), (companies, 12), (digital, 12)...</td>\n",
       "      <td>[(Business, 53), (Finance, 48), (Technology, 4...</td>\n",
       "      <td>[(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-02</th>\n",
       "      <td>[(Bitcoin, 37), (United, 17), (States, 17), (J...</td>\n",
       "      <td>[(company, 15), (Bitcoin, 15), (investors, 9),...</td>\n",
       "      <td>[(Business, 39), (Finance, 36), (Computers, 31...</td>\n",
       "      <td>[(us, 28), (gb, 3), (in, 2), (au, 1), (pt, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-03</th>\n",
       "      <td>[(Bitcoin, 15), (Cryptocurrency, 6), (For, 3),...</td>\n",
       "      <td>[(data, 5), (services, 5), (business, 3), (Pet...</td>\n",
       "      <td>[(Business, 16), (Information Technology, 14),...</td>\n",
       "      <td>[(us, 13), (ru, 1), (fr, 1), (ca, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-04</th>\n",
       "      <td>[(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...</td>\n",
       "      <td>[(data, 3), (President, 2), (companies, 2), (c...</td>\n",
       "      <td>[(Business, 19), (Finance, 18), (E-commerce, 1...</td>\n",
       "      <td>[(us, 15), (in, 1), (ph, 1), (ng, 1), (cn, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-05</th>\n",
       "      <td>[(Bitcoin, 33), (Anonymity, 11), (United, 10),...</td>\n",
       "      <td>[(company, 8), (state, 7), (users, 7), (collab...</td>\n",
       "      <td>[(Business, 33), (Finance, 33), (Information T...</td>\n",
       "      <td>[(us, 18), (ca, 3), (in, 2), (gb, 2), (be, 1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     concepts  \\\n",
       "date                                                            \n",
       "2017-02-01  [(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...   \n",
       "2017-02-02  [(Bitcoin, 37), (United, 17), (States, 17), (J...   \n",
       "2017-02-03  [(Bitcoin, 15), (Cryptocurrency, 6), (For, 3),...   \n",
       "2017-02-04  [(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...   \n",
       "2017-02-05  [(Bitcoin, 33), (Anonymity, 11), (United, 10),...   \n",
       "\n",
       "                                                  key_phrases  \\\n",
       "date                                                            \n",
       "2017-02-01  [(company, 13), (companies, 12), (digital, 12)...   \n",
       "2017-02-02  [(company, 15), (Bitcoin, 15), (investors, 9),...   \n",
       "2017-02-03  [(data, 5), (services, 5), (business, 3), (Pet...   \n",
       "2017-02-04  [(data, 3), (President, 2), (companies, 2), (c...   \n",
       "2017-02-05  [(company, 8), (state, 7), (users, 7), (collab...   \n",
       "\n",
       "                                                   categories  \\\n",
       "date                                                            \n",
       "2017-02-01  [(Business, 53), (Finance, 48), (Technology, 4...   \n",
       "2017-02-02  [(Business, 39), (Finance, 36), (Computers, 31...   \n",
       "2017-02-03  [(Business, 16), (Information Technology, 14),...   \n",
       "2017-02-04  [(Business, 19), (Finance, 18), (E-commerce, 1...   \n",
       "2017-02-05  [(Business, 33), (Finance, 33), (Information T...   \n",
       "\n",
       "                                                      country  \n",
       "date                                                           \n",
       "2017-02-01  [(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...  \n",
       "2017-02-02  [(us, 28), (gb, 3), (in, 2), (au, 1), (pt, 1),...  \n",
       "2017-02-03              [(us, 13), (ru, 1), (fr, 1), (ca, 1)]  \n",
       "2017-02-04  [(us, 15), (in, 1), (ph, 1), (ng, 1), (cn, 1),...  \n",
       "2017-02-05  [(us, 18), (ca, 3), (in, 2), (gb, 2), (be, 1),...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic = df_concept.join(df_keyword).join(df_category).join(df_country)\n",
    "df_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic.to_pickle('df_daily_news_topic.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
