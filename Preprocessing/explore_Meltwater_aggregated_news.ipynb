{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kexin Yu\"\n",
    "__version__ = \"CS341, Stanford, Spring 2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_home = 'news-coin-aggregations'\n",
    "social_data_home = 'social-coin-aggregations'\n",
    "\n",
    "coin_of_interest = 'BTC.jsonl'\n",
    "\n",
    "def json_read_multiple_records(file):\n",
    "    for line in open(file, mode=\"r\"):\n",
    "        yield json.loads(line)   \n",
    "        \n",
    "records = list(json_read_multiple_records(os.path.join(news_data_home, coin_of_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['concepts', 'count', 'categories', 'per_hour_sentiment', 'per_hour_reach', 'key_phrases', 'country'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]['views'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1523905200000', '1523919600000', '1523912400000', '1523858400000', '1523836800000', '1523883600000', '1523847600000', '1523872800000', '1523840400000', '1523890800000', '1523854800000', '1523865600000', '1523876400000', '1523894400000', '1523908800000', '1523916000000', '1523844000000', '1523862000000', '1523901600000', '1523869200000', '1523898000000', '1523923200000', '1523887200000', '1523880000000', '1523851200000'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day0_sentiment_dict = records[0]['views']['per_hour_sentiment']['subViews']\n",
    "day0_sentiment_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-hour sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  neutral  positive  negative  sentiment_mean\n",
      "datetime                                                              \n",
      "1485993600000  2017-02-01      0.0       0.0       0.0    0.000000e+00\n",
      "1485997200000  2017-02-01      2.0       4.0       0.0    6.666667e-01\n",
      "1486000800000  2017-02-01      0.0       0.0       0.0    0.000000e+00\n",
      "1486004400000  2017-02-01      1.0       0.0       0.0    0.000000e+00\n",
      "1486008000000  2017-02-01      1.0       0.0       0.0    9.694558e-07\n",
      "                     date  neutral  positive  negative  sentiment_mean\n",
      "datetime                                                              \n",
      "1523908800000  2018-04-16    233.0     152.0      27.0        0.302729\n",
      "1523912400000  2018-04-16    598.0      38.0      13.0        0.038287\n",
      "1523916000000  2018-04-16    512.0      11.0       5.0        0.011715\n",
      "1523919600000  2018-04-16    296.0       8.0      20.0       -0.034630\n",
      "1523923200000  2018-04-16      0.0       0.0       0.0        0.000000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sentiments = []\n",
    "\n",
    "for record in records:\n",
    "    daily_sentiment_dict = record['views']['per_hour_sentiment']['subViews']\n",
    "    \n",
    "    hour_ids = []\n",
    "    frames = []\n",
    "\n",
    "    for hour_id, d in daily_sentiment_dict.items():\n",
    "        hour_ids.append(hour_id)\n",
    "        frames.append(flatten_dict(d))\n",
    "\n",
    "    df = pd.DataFrame(frames)\n",
    "\n",
    "    df['datetime'] = pd.Series(hour_ids)\n",
    "    df['date'] = pd.Series([datetime.fromtimestamp(float(h)/1000).strftime('%Y-%m-%d') for h in hour_ids])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['counts_type', 'mean_type'], inplace=True)\n",
    "    \n",
    "    sentiments.append(df)\n",
    "    \n",
    "df_sentiment = pd.concat(sentiments)\n",
    "df_sentiment.drop(columns=['counts_counts_u'], inplace=True)\n",
    "df_sentiment.sort_index(inplace=True)\n",
    "df_sentiment.rename(columns={'counts_counts_n': 'neutral', \n",
    "                   'counts_counts_p': 'positive',\n",
    "                   'counts_counts_v': 'negative',\n",
    "                   'mean_statistics_MEAN': 'sentiment_mean'\n",
    "                  }, inplace=True)\n",
    "cols = ['date', 'neutral', 'positive', 'negative', 'sentiment_mean']\n",
    "df_sentiment = df_sentiment[cols]\n",
    "df_sentiment.fillna(0, inplace=True)\n",
    "print(df_sentiment.head())\n",
    "print(df_sentiment.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-hour document reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  reach_count\n",
      "datetime                              \n",
      "1485993600000  2017-02-01          0.0\n",
      "1485997200000  2017-02-01     724308.0\n",
      "1486000800000  2017-02-01          0.0\n",
      "1486004400000  2017-02-01      11832.0\n",
      "1486008000000  2017-02-01      77971.0\n",
      "                     date  reach_count\n",
      "datetime                              \n",
      "1523908800000  2018-04-16  201147442.0\n",
      "1523912400000  2018-04-16  327878870.0\n",
      "1523916000000  2018-04-16  244126008.0\n",
      "1523919600000  2018-04-16  150643500.0\n",
      "1523923200000  2018-04-16          0.0\n"
     ]
    }
   ],
   "source": [
    "records[0]['views']['per_hour_reach']['subViews']\n",
    "\n",
    "reach = []\n",
    "\n",
    "for record in records:\n",
    "    daily_reach_dict = record['views']['per_hour_reach']['subViews']\n",
    "    \n",
    "    hour_ids = []\n",
    "    frames = []\n",
    "\n",
    "    for hour_id, d in daily_reach_dict.items():\n",
    "        hour_ids.append(hour_id)\n",
    "        frames.append(flatten_dict(d))\n",
    "\n",
    "    df = pd.DataFrame(frames)\n",
    "\n",
    "    df['datetime'] = pd.Series(hour_ids)\n",
    "    df['date'] = pd.Series([datetime.fromtimestamp(float(h)/1000).strftime('%Y-%m-%d') for h in hour_ids])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['sum_type'], inplace=True)\n",
    "    \n",
    "    reach.append(df)\n",
    "    \n",
    "df_reach = pd.concat(reach)\n",
    "df_reach.sort_index(inplace=True)\n",
    "df_reach.rename(columns={'sum_statistics_SUM': 'reach_count'}, inplace=True)\n",
    "cols = ['date', 'reach_count']\n",
    "df_reach = df_reach[cols]\n",
    "df_reach.fillna(0, inplace=True)\n",
    "print(df_reach.head())\n",
    "print(df_reach.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>reach_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523908800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>233.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.302729</td>\n",
       "      <td>201147442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523912400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>598.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>327878870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523916000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>244126008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523919600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>296.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.034630</td>\n",
       "      <td>150643500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523923200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  neutral  positive  negative  sentiment_mean  \\\n",
       "datetime                                                                 \n",
       "1523908800000  2018-04-16    233.0     152.0      27.0        0.302729   \n",
       "1523912400000  2018-04-16    598.0      38.0      13.0        0.038287   \n",
       "1523916000000  2018-04-16    512.0      11.0       5.0        0.011715   \n",
       "1523919600000  2018-04-16    296.0       8.0      20.0       -0.034630   \n",
       "1523923200000  2018-04-16      0.0       0.0       0.0        0.000000   \n",
       "\n",
       "               reach_count  \n",
       "datetime                    \n",
       "1523908800000  201147442.0  \n",
       "1523912400000  327878870.0  \n",
       "1523916000000  244126008.0  \n",
       "1523919600000  150643500.0  \n",
       "1523923200000          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_reach = df_sentiment.join(df_reach, lsuffix='', rsuffix='_r')\n",
    "df_sent_reach.drop([col for col in df_sent_reach.columns if '_r' in col],axis=1,inplace=True)\n",
    "df_sent_reach.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>reach_count</th>\n",
       "      <th>daily_reach_count</th>\n",
       "      <th>daily_sentiment_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523908800000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>233.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.302729</td>\n",
       "      <td>201147442.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.114077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523912400000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>598.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>327878870.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.114077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523916000000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>244126008.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.114077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523919600000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>296.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.034630</td>\n",
       "      <td>150643500.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.114077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523923200000</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.241967e+09</td>\n",
       "      <td>0.114077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  neutral  positive  negative  sentiment_mean  \\\n",
       "datetime                                                                 \n",
       "1523908800000  2018-04-16    233.0     152.0      27.0        0.302729   \n",
       "1523912400000  2018-04-16    598.0      38.0      13.0        0.038287   \n",
       "1523916000000  2018-04-16    512.0      11.0       5.0        0.011715   \n",
       "1523919600000  2018-04-16    296.0       8.0      20.0       -0.034630   \n",
       "1523923200000  2018-04-16      0.0       0.0       0.0        0.000000   \n",
       "\n",
       "               reach_count  daily_reach_count  daily_sentiment_mean  \n",
       "datetime                                                             \n",
       "1523908800000  201147442.0       4.241967e+09              0.114077  \n",
       "1523912400000  327878870.0       4.241967e+09              0.114077  \n",
       "1523916000000  244126008.0       4.241967e+09              0.114077  \n",
       "1523919600000  150643500.0       4.241967e+09              0.114077  \n",
       "1523923200000          0.0       4.241967e+09              0.114077  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_reach['daily_reach_count'] = df_sent_reach['reach_count'].groupby(df_sent_reach['date']).transform('sum')\n",
    "df_sent_reach['daily_sentiment_mean'] = df_sent_reach['sentiment_mean'].groupby(df_sent_reach['date']).transform('mean')\n",
    "df_sent_reach.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_reach.to_pickle('df_hourly_news_sentiment_reach.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_bag_of_words(word_of_interest):\n",
    "    \"\"\"Collect all words from the given category and sort by count. \n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    timestamps = []\n",
    "\n",
    "    for record in records:\n",
    "        dict_ = record['views'][word_of_interest]['counts']\n",
    "        sorted_dict = sorted(dict_.items(), key=lambda x: x[1], reverse=True)\n",
    "        lst.append(sorted_dict)\n",
    "        timestamps.append(sorted(list(record['views']['per_hour_sentiment']['counts'].keys()))[0])\n",
    "    \n",
    "    dates = [datetime.fromtimestamp(float(ts)/1000).strftime('%Y-%m-%d') for ts in timestamps]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {'date': dates,\n",
    "         word_of_interest: lst,\n",
    "        })\n",
    "\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "                                \n",
    "    return df\n",
    "\n",
    "def phrase_to_words(df, word_of_interest):\n",
    "    \"\"\"Split phrase to words. \n",
    "    Example: ('Has Been', 17) -> ('Has', 17), ('Been', 17)\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        l1 = []\n",
    "        for pair in row[word_of_interest]:\n",
    "            l2 = []\n",
    "            for word in pair[0].split():\n",
    "                l2.append((word, pair[1]))\n",
    "            l1.extend(l2)\n",
    "        row[word_of_interest] = l1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     concepts\n",
      "date                                                         \n",
      "2017-02-01  [(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...\n",
      "2017-02-02  [(Bitcoin, 37), (United, 17), (States, 17), (J...\n",
      "2017-02-03  [(Bitcoin, 15), (Cryptocurrency, 6), (Japan, 3...\n",
      "2017-02-04  [(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...\n",
      "2017-02-05  [(Bitcoin, 33), (Anonymity, 11), (Hacker, 10),...\n",
      "                                                     concepts\n",
      "date                                                         \n",
      "2018-04-11  [(Cryptocurrency, 11223), (Bitcoin, 9098), (Un...\n",
      "2018-04-12  [(Cryptocurrency, 12276), (Bitcoin, 9985), (Tw...\n",
      "2018-04-13  [(Cryptocurrency, 6498), (Bitcoin, 4296), (Uni...\n",
      "2018-04-14  [(Cryptocurrency, 5758), (Bitcoin, 3738), (Uni...\n",
      "2018-04-15  [(Cryptocurrency, 13378), (Bitcoin, 10470), (U...\n"
     ]
    }
   ],
   "source": [
    "df_concept = get_bag_of_words('concepts')\n",
    "df_concept = phrase_to_words(df_concept, 'concepts')\n",
    "print(df_concept.head())\n",
    "print(df_concept.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  key_phrases\n",
      "date                                                         \n",
      "2017-02-01  [(company, 13), (digital, 12), (currency, 12),...\n",
      "2017-02-02  [(Bitcoin, 15), (company, 15), (investors, 9),...\n",
      "2017-02-03  [(data, 5), (services, 5), (business, 3), (Tru...\n",
      "2017-02-04  [(data, 3), (people, 2), (Bitcoin, 2), (accoun...\n",
      "2017-02-05  [(company, 8), (state, 7), (collaborative, 7),...\n",
      "                                                  key_phrases\n",
      "date                                                         \n",
      "2018-04-11  [(dollar, 2334), (Investors, 2287), (exchanges...\n",
      "2018-04-12  [(dollar, 2613), (exchanges, 2487), (Investors...\n",
      "2018-04-13  [(dollar, 2464), (Investors, 2365), (exchanges...\n",
      "2018-04-14  [(dollar, 2360), (Investors, 2254), (exchanges...\n",
      "2018-04-15  [(dollar, 2852), (Investors, 2822), (exchanges...\n"
     ]
    }
   ],
   "source": [
    "df_keyword = get_bag_of_words('key_phrases')\n",
    "df_keyword = phrase_to_words(df_keyword, 'key_phrases')\n",
    "print(df_keyword.head())\n",
    "print(df_keyword.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   categories\n",
      "date                                                         \n",
      "2017-02-01  [(Business, 53), (Finance, 48), (Technology, 4...\n",
      "2017-02-02  [(Business, 39), (Finance, 36), (Information T...\n",
      "2017-02-03  [(Business, 16), (Information Technology, 14),...\n",
      "2017-02-04  [(Business, 19), (Finance, 18), (E-commerce, 1...\n",
      "2017-02-05  [(Business, 33), (Finance, 33), (Information T...\n",
      "                                                   categories\n",
      "date                                                         \n",
      "2018-04-11  [(Business, 9238), (Finance, 9044), (Informati...\n",
      "2018-04-12  [(Business, 10136), (Finance, 9918), (Informat...\n",
      "2018-04-13  [(Business, 4472), (Finance, 4162), (Informati...\n",
      "2018-04-14  [(Business, 3809), (Finance, 3646), (Informati...\n",
      "2018-04-15  [(Business, 10886), (Finance, 10488), (Technol...\n"
     ]
    }
   ],
   "source": [
    "df_category = get_bag_of_words('categories')\n",
    "print(df_category.head())\n",
    "print(df_category.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      country\n",
      "date                                                         \n",
      "2017-02-01  [(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...\n",
      "2017-02-02  [(us, 28), (gb, 3), (in, 2), (pt, 1), (au, 1),...\n",
      "2017-02-03              [(us, 13), (ca, 1), (fr, 1), (ru, 1)]\n",
      "2017-02-04  [(us, 15), (fr, 1), (id, 1), (ng, 1), (ph, 1),...\n",
      "2017-02-05  [(us, 18), (ca, 3), (in, 2), (gb, 2), (pt, 1),...\n",
      "                                                      country\n",
      "date                                                         \n",
      "2018-04-11  [(us, 7540), (gb, 292), (ng, 247), (in, 191), ...\n",
      "2018-04-12  [(us, 8463), (gb, 237), (ng, 205), (in, 180), ...\n",
      "2018-04-13  [(us, 3660), (ng, 244), (in, 88), (gb, 68), (a...\n",
      "2018-04-14  [(us, 3114), (ng, 111), (in, 80), (gb, 74), (s...\n",
      "2018-04-15  [(us, 9522), (gb, 210), (ng, 186), (ca, 159), ...\n"
     ]
    }
   ],
   "source": [
    "df_country= get_bag_of_words('country')\n",
    "print(df_country.head())\n",
    "print(df_country.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concepts</th>\n",
       "      <th>key_phrases</th>\n",
       "      <th>categories</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>[(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...</td>\n",
       "      <td>[(company, 13), (digital, 12), (currency, 12),...</td>\n",
       "      <td>[(Business, 53), (Finance, 48), (Technology, 4...</td>\n",
       "      <td>[(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-02</th>\n",
       "      <td>[(Bitcoin, 37), (United, 17), (States, 17), (J...</td>\n",
       "      <td>[(Bitcoin, 15), (company, 15), (investors, 9),...</td>\n",
       "      <td>[(Business, 39), (Finance, 36), (Information T...</td>\n",
       "      <td>[(us, 28), (gb, 3), (in, 2), (pt, 1), (au, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-03</th>\n",
       "      <td>[(Bitcoin, 15), (Cryptocurrency, 6), (Japan, 3...</td>\n",
       "      <td>[(data, 5), (services, 5), (business, 3), (Tru...</td>\n",
       "      <td>[(Business, 16), (Information Technology, 14),...</td>\n",
       "      <td>[(us, 13), (ca, 1), (fr, 1), (ru, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-04</th>\n",
       "      <td>[(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...</td>\n",
       "      <td>[(data, 3), (people, 2), (Bitcoin, 2), (accoun...</td>\n",
       "      <td>[(Business, 19), (Finance, 18), (E-commerce, 1...</td>\n",
       "      <td>[(us, 15), (fr, 1), (id, 1), (ng, 1), (ph, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-05</th>\n",
       "      <td>[(Bitcoin, 33), (Anonymity, 11), (Hacker, 10),...</td>\n",
       "      <td>[(company, 8), (state, 7), (collaborative, 7),...</td>\n",
       "      <td>[(Business, 33), (Finance, 33), (Information T...</td>\n",
       "      <td>[(us, 18), (ca, 3), (in, 2), (gb, 2), (pt, 1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     concepts  \\\n",
       "date                                                            \n",
       "2017-02-01  [(Bitcoin, 48), (Has, 17), (Been, 17), (Canada...   \n",
       "2017-02-02  [(Bitcoin, 37), (United, 17), (States, 17), (J...   \n",
       "2017-02-03  [(Bitcoin, 15), (Cryptocurrency, 6), (Japan, 3...   \n",
       "2017-02-04  [(Bitcoin, 18), (Cryptocurrency, 9), (Hacker, ...   \n",
       "2017-02-05  [(Bitcoin, 33), (Anonymity, 11), (Hacker, 10),...   \n",
       "\n",
       "                                                  key_phrases  \\\n",
       "date                                                            \n",
       "2017-02-01  [(company, 13), (digital, 12), (currency, 12),...   \n",
       "2017-02-02  [(Bitcoin, 15), (company, 15), (investors, 9),...   \n",
       "2017-02-03  [(data, 5), (services, 5), (business, 3), (Tru...   \n",
       "2017-02-04  [(data, 3), (people, 2), (Bitcoin, 2), (accoun...   \n",
       "2017-02-05  [(company, 8), (state, 7), (collaborative, 7),...   \n",
       "\n",
       "                                                   categories  \\\n",
       "date                                                            \n",
       "2017-02-01  [(Business, 53), (Finance, 48), (Technology, 4...   \n",
       "2017-02-02  [(Business, 39), (Finance, 36), (Information T...   \n",
       "2017-02-03  [(Business, 16), (Information Technology, 14),...   \n",
       "2017-02-04  [(Business, 19), (Finance, 18), (E-commerce, 1...   \n",
       "2017-02-05  [(Business, 33), (Finance, 33), (Information T...   \n",
       "\n",
       "                                                      country  \n",
       "date                                                           \n",
       "2017-02-01  [(us, 26), (au, 7), (in, 5), (gb, 5), (ng, 2),...  \n",
       "2017-02-02  [(us, 28), (gb, 3), (in, 2), (pt, 1), (au, 1),...  \n",
       "2017-02-03              [(us, 13), (ca, 1), (fr, 1), (ru, 1)]  \n",
       "2017-02-04  [(us, 15), (fr, 1), (id, 1), (ng, 1), (ph, 1),...  \n",
       "2017-02-05  [(us, 18), (ca, 3), (in, 2), (gb, 2), (pt, 1),...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic = df_concept.join(df_keyword).join(df_category).join(df_country)\n",
    "df_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic.to_pickle('df_daily_news_topic.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
